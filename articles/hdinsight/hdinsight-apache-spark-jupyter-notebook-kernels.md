---
title: clusters aaaKernels para bloco de notas do Jupyter no Spark no Azure HDInsight | Microsoft Docs
description: "Saiba mais sobre a kernels PySpark, PySpark3 e Spark Olá para bloco de notas do Jupyter disponível com clusters do Spark no Azure HDInsight."
keywords: Bloco de notas do jupyter no spark, spark do jupyter
services: hdinsight
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: 0719e503-ee6d-41ac-b37e-3d77db8b121b
ms.service: hdinsight
ms.custom: hdinsightactive,hdiseo17may2017
ms.workload: big-data
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 05/15/2017
ms.author: nitinme
ms.openlocfilehash: 560c944fe850c5753ac9fa90550b804f0c47d14c
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: pt-PT
ms.lasthandoff: 10/06/2017
---
# <a name="kernels-for-jupyter-notebook-on-spark-clusters-in-azure-hdinsight"></a><span data-ttu-id="966c3-104">Kernels para bloco de notas do Jupyter nos clusters do Spark no Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="966c3-104">Kernels for Jupyter notebook on Spark clusters in Azure HDInsight</span></span> 

<span data-ttu-id="966c3-105">Clusters do HDInsight Spark fornecem kernels que pode utilizar com o bloco de notas do Jupyter Olá no Spark para testar as suas aplicações.</span><span class="sxs-lookup"><span data-stu-id="966c3-105">HDInsight Spark clusters provide kernels that you can use with hello Jupyter notebook on Spark for testing your applications.</span></span> <span data-ttu-id="966c3-106">Um kernel é um programa que executa e interpreta o seu código.</span><span class="sxs-lookup"><span data-stu-id="966c3-106">A kernel is a program that runs and interprets your code.</span></span> <span data-ttu-id="966c3-107">três kernels Olá são:</span><span class="sxs-lookup"><span data-stu-id="966c3-107">hello three kernels are:</span></span>

- <span data-ttu-id="966c3-108">**PySpark** – para aplicações escritas no Python2</span><span class="sxs-lookup"><span data-stu-id="966c3-108">**PySpark** - for applications written in Python2</span></span>
- <span data-ttu-id="966c3-109">**PySpark3** – para aplicações escritas no Python3</span><span class="sxs-lookup"><span data-stu-id="966c3-109">**PySpark3** - for applications written in Python3</span></span>
- <span data-ttu-id="966c3-110">**O Spark** – para aplicações escritas no Scala</span><span class="sxs-lookup"><span data-stu-id="966c3-110">**Spark** - for applications written in Scala</span></span>

<span data-ttu-id="966c3-111">Neste artigo, saiba como toouse estes kernels e os benefícios de Olá de utilizá-los.</span><span class="sxs-lookup"><span data-stu-id="966c3-111">In this article, you learn how toouse these kernels and hello benefits of using them.</span></span>

## <a name="prerequisites"></a><span data-ttu-id="966c3-112">Pré-requisitos</span><span class="sxs-lookup"><span data-stu-id="966c3-112">Prerequisites</span></span>

* <span data-ttu-id="966c3-113">Um cluster do Apache Spark no HDInsight.</span><span class="sxs-lookup"><span data-stu-id="966c3-113">An Apache Spark cluster in HDInsight.</span></span> <span data-ttu-id="966c3-114">Para obter instruções, consulte [clusters do Apache Spark criar no Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="966c3-114">For instructions, see [Create Apache Spark clusters in Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span>

## <a name="create-a-jupyter-notebook-on-spark-hdinsight"></a><span data-ttu-id="966c3-115">Criar um bloco de notas do Jupyter no Spark HDInsight</span><span class="sxs-lookup"><span data-stu-id="966c3-115">Create a Jupyter notebook on Spark HDInsight</span></span>

1. <span data-ttu-id="966c3-116">De Olá [portal do Azure](https://portal.azure.com/), abra o seu cluster.</span><span class="sxs-lookup"><span data-stu-id="966c3-116">From hello [Azure portal](https://portal.azure.com/), open your cluster.</span></span>  <span data-ttu-id="966c3-117">Consulte [clusters lista e mostrar](hdinsight-administer-use-portal-linux.md#list-and-show-clusters) para obter instruções de Olá.</span><span class="sxs-lookup"><span data-stu-id="966c3-117">See [List and show clusters](hdinsight-administer-use-portal-linux.md#list-and-show-clusters) for hello instructions.</span></span> <span data-ttu-id="966c3-118">cluster Olá está aberto num novo painel do portal.</span><span class="sxs-lookup"><span data-stu-id="966c3-118">hello cluster is opened in a new portal blade.</span></span>

2. <span data-ttu-id="966c3-119">De Olá **ligações rápidas** secção, clique em **Cluster dashboards** tooopen Olá **Cluster dashboards** painel.</span><span class="sxs-lookup"><span data-stu-id="966c3-119">From hello **Quick links** section, click **Cluster dashboards** tooopen hello **Cluster dashboards** blade.</span></span>  <span data-ttu-id="966c3-120">Se não vir **ligações rápidas**, clique em **descrição geral** no menu à esquerda do Olá no painel de Olá.</span><span class="sxs-lookup"><span data-stu-id="966c3-120">If you don't see **Quick Links**, click **Overview** from hello left menu on hello blade.</span></span>

    <span data-ttu-id="966c3-121">![Bloco de notas do Jupyter no Spark](./media/hdinsight-apache-spark-jupyter-notebook-kernels/hdinsight-jupyter-notebook-on-spark.png "bloco de notas do Jupyter no Spark")</span><span class="sxs-lookup"><span data-stu-id="966c3-121">![Jupyter notebook on Spark](./media/hdinsight-apache-spark-jupyter-notebook-kernels/hdinsight-jupyter-notebook-on-spark.png "Jupyter notebook on Spark")</span></span> 

3. <span data-ttu-id="966c3-122">Clique em **bloco de notas do Jupyter**.</span><span class="sxs-lookup"><span data-stu-id="966c3-122">Click **Jupyter Notebook**.</span></span> <span data-ttu-id="966c3-123">Se lhe for solicitado, introduza as credenciais de administrador Olá para cluster Olá.</span><span class="sxs-lookup"><span data-stu-id="966c3-123">If prompted, enter hello admin credentials for hello cluster.</span></span>
   
   > [!NOTE]
   > <span data-ttu-id="966c3-124">Também pode aceder notas do Jupyter Olá no cluster do Spark por abrir Olá seguinte URL no browser.</span><span class="sxs-lookup"><span data-stu-id="966c3-124">You may also reach hello Jupyter notebook on Spark cluster by opening hello following URL in your browser.</span></span> <span data-ttu-id="966c3-125">Substitua **CLUSTERNAME** com o nome de Olá do cluster:</span><span class="sxs-lookup"><span data-stu-id="966c3-125">Replace **CLUSTERNAME** with hello name of your cluster:</span></span>
   >
   > `https://CLUSTERNAME.azurehdinsight.net/jupyter`
   > 
   > 

3. <span data-ttu-id="966c3-126">Clique em **novo**e, em seguida, clique em **Pyspark**, **PySpark3**, ou **Spark** toocreate um bloco de notas.</span><span class="sxs-lookup"><span data-stu-id="966c3-126">Click **New**, and then click either **Pyspark**, **PySpark3**, or **Spark** toocreate a notebook.</span></span> <span data-ttu-id="966c3-127">Utilize o kernel do Spark Olá para aplicações de Scala, kernel do PySpark para aplicações de Python2 e PySpark3 kernel para aplicações de Python3.</span><span class="sxs-lookup"><span data-stu-id="966c3-127">Use hello Spark kernel for Scala applications, PySpark kernel for Python2 applications, and PySpark3 kernel for Python3 applications.</span></span>
   
    <span data-ttu-id="966c3-128">![Kernels para bloco de notas do Jupyter no Spark](./media/hdinsight-apache-spark-jupyter-notebook-kernels/kernel-jupyter-notebook-on-spark.png "Kernels para bloco de notas do Jupyter no Spark")</span><span class="sxs-lookup"><span data-stu-id="966c3-128">![Kernels for Jupyter notebook on Spark](./media/hdinsight-apache-spark-jupyter-notebook-kernels/kernel-jupyter-notebook-on-spark.png "Kernels for Jupyter notebook on Spark")</span></span> 

4. <span data-ttu-id="966c3-129">Um bloco de notas abre-se com o kernel Olá que selecionou.</span><span class="sxs-lookup"><span data-stu-id="966c3-129">A notebook opens with hello kernel you selected.</span></span>

## <a name="benefits-of-using-hello-kernels"></a><span data-ttu-id="966c3-130">Vantagens da utilização kernels Olá</span><span class="sxs-lookup"><span data-stu-id="966c3-130">Benefits of using hello kernels</span></span>

<span data-ttu-id="966c3-131">Seguem-se alguns benefícios da utilização kernels novo Olá com o bloco de notas do Jupyter nos clusters do Spark HDInsight.</span><span class="sxs-lookup"><span data-stu-id="966c3-131">Here are a few benefits of using hello new kernels with Jupyter notebook on Spark HDInsight clusters.</span></span>

- <span data-ttu-id="966c3-132">**Configuração predefinida contextos**.</span><span class="sxs-lookup"><span data-stu-id="966c3-132">**Preset contexts**.</span></span> <span data-ttu-id="966c3-133">Com **PySpark**, **PySpark3**, ou Olá **Spark** kernels, não precisa de contextos de Spark ou Hive da Olá tooset explicitamente antes de começar a trabalhar com as suas aplicações.</span><span class="sxs-lookup"><span data-stu-id="966c3-133">With  **PySpark**, **PySpark3**, or hello **Spark** kernels, you do not need tooset hello Spark or Hive contexts explicitly before you start working with your applications.</span></span> <span data-ttu-id="966c3-134">Estes estiverem disponíveis por predefinição.</span><span class="sxs-lookup"><span data-stu-id="966c3-134">These are available by default.</span></span> <span data-ttu-id="966c3-135">Estes contextos são:</span><span class="sxs-lookup"><span data-stu-id="966c3-135">These contexts are:</span></span>
   
   * <span data-ttu-id="966c3-136">**sc** – para o contexto do Spark</span><span class="sxs-lookup"><span data-stu-id="966c3-136">**sc** - for Spark context</span></span>
   * <span data-ttu-id="966c3-137">**sqlContext** – para o contexto de ramo de registo</span><span class="sxs-lookup"><span data-stu-id="966c3-137">**sqlContext** - for Hive context</span></span>

    <span data-ttu-id="966c3-138">Por isso, não tem instruções de toorun como Olá contextos de Olá tooset os seguintes:</span><span class="sxs-lookup"><span data-stu-id="966c3-138">So, you don't have toorun statements like hello following tooset hello contexts:</span></span>

        <span data-ttu-id="966c3-139">sc = SparkContext('yarn-client') sqlContext = HiveContext(sc)</span><span class="sxs-lookup"><span data-stu-id="966c3-139">sc = SparkContext('yarn-client')    sqlContext = HiveContext(sc)</span></span>

    <span data-ttu-id="966c3-140">Em vez disso, pode utilizar diretamente Olá contextos na sua aplicação da configuração predefinida.</span><span class="sxs-lookup"><span data-stu-id="966c3-140">Instead, you can directly use hello preset contexts in your application.</span></span>

- <span data-ttu-id="966c3-141">**Magia de células**.</span><span class="sxs-lookup"><span data-stu-id="966c3-141">**Cell magics**.</span></span> <span data-ttu-id="966c3-142">Olá kernel do PySpark fornece algumas predefinidas "magia", que são comandos especiais que pode chamar com `%%` (por exemplo, `%%MAGIC` <args>).</span><span class="sxs-lookup"><span data-stu-id="966c3-142">hello PySpark kernel provides some predefined “magics”, which are special commands that you can call with `%%` (for example, `%%MAGIC` <args>).</span></span> <span data-ttu-id="966c3-143">comando mágica Olá tem de ser Olá primeiro numa célula de código e permitir várias linhas de conteúdo.</span><span class="sxs-lookup"><span data-stu-id="966c3-143">hello magic command must be hello first word in a code cell and allow for multiple lines of content.</span></span> <span data-ttu-id="966c3-144">word mágica Olá deverá ser Olá primeiro numa célula de Olá.</span><span class="sxs-lookup"><span data-stu-id="966c3-144">hello magic word should be hello first word in hello cell.</span></span> <span data-ttu-id="966c3-145">Adicionar nada antes de magic Olá, mesmo comentários, causa um erro.</span><span class="sxs-lookup"><span data-stu-id="966c3-145">Adding anything before hello magic, even comments, causes an error.</span></span>     <span data-ttu-id="966c3-146">Para obter mais informações sobre a magia, consulte [aqui](http://ipython.readthedocs.org/en/stable/interactive/magics.html).</span><span class="sxs-lookup"><span data-stu-id="966c3-146">For more information on magics, see [here](http://ipython.readthedocs.org/en/stable/interactive/magics.html).</span></span>
   
    <span data-ttu-id="966c3-147">Olá tabela seguinte lista magia diferentes Olá disponível através de kernels Olá.</span><span class="sxs-lookup"><span data-stu-id="966c3-147">hello following table lists hello different magics available through hello kernels.</span></span>

   | <span data-ttu-id="966c3-148">Magic</span><span class="sxs-lookup"><span data-stu-id="966c3-148">Magic</span></span> | <span data-ttu-id="966c3-149">Exemplo</span><span class="sxs-lookup"><span data-stu-id="966c3-149">Example</span></span> | <span data-ttu-id="966c3-150">Descrição</span><span class="sxs-lookup"><span data-stu-id="966c3-150">Description</span></span> |
   | --- | --- | --- |
   | <span data-ttu-id="966c3-151">Ajuda</span><span class="sxs-lookup"><span data-stu-id="966c3-151">help</span></span> |`%%help` |<span data-ttu-id="966c3-152">Gera uma tabela de todos os magia disponíveis Olá com exemplo e descrição</span><span class="sxs-lookup"><span data-stu-id="966c3-152">Generates a table of all hello available magics with example and description</span></span> |
   | <span data-ttu-id="966c3-153">informações</span><span class="sxs-lookup"><span data-stu-id="966c3-153">info</span></span> |`%%info` |<span data-ttu-id="966c3-154">Informações da sessão para o ponto final de Livy atual Olá saídas</span><span class="sxs-lookup"><span data-stu-id="966c3-154">Outputs session information for hello current Livy endpoint</span></span> |
   | <span data-ttu-id="966c3-155">Configurar</span><span class="sxs-lookup"><span data-stu-id="966c3-155">configure</span></span> |`%%configure -f`<br><span data-ttu-id="966c3-156">`{"executorMemory": "1000M"`,</span><span class="sxs-lookup"><span data-stu-id="966c3-156">`{"executorMemory": "1000M"`,</span></span><br><span data-ttu-id="966c3-157">`"executorCores": 4`}</span><span class="sxs-lookup"><span data-stu-id="966c3-157">`"executorCores": 4`}</span></span> |<span data-ttu-id="966c3-158">Configura os parâmetros de Olá para criar uma sessão.</span><span class="sxs-lookup"><span data-stu-id="966c3-158">Configures hello parameters for creating a session.</span></span> <span data-ttu-id="966c3-159">Olá sinalizador force (-f) é obrigatório se já tiver sido criada uma sessão, que garante que sessão Olá é removido e recriado.</span><span class="sxs-lookup"><span data-stu-id="966c3-159">hello force flag (-f) is mandatory if a session has already been created, which ensures that hello session is dropped and recreated.</span></span> <span data-ttu-id="966c3-160">Observe [POST /sessions de Livy corpo do pedido](https://github.com/cloudera/livy#request-body) para obter uma lista de parâmetros válidos.</span><span class="sxs-lookup"><span data-stu-id="966c3-160">Look at [Livy's POST /sessions Request Body](https://github.com/cloudera/livy#request-body) for a list of valid parameters.</span></span> <span data-ttu-id="966c3-161">Os parâmetros devem ser transmitidos como uma cadeia JSON e tem de estar na linha seguinte Olá após magic Olá, conforme apresentado na coluna de exemplo de Olá.</span><span class="sxs-lookup"><span data-stu-id="966c3-161">Parameters must be passed in as a JSON string and must be on hello next line after hello magic, as shown in hello example column.</span></span> |
   | <span data-ttu-id="966c3-162">SQL Server</span><span class="sxs-lookup"><span data-stu-id="966c3-162">sql</span></span> |`%%sql -o <variable name>`<br> `SHOW TABLES` |<span data-ttu-id="966c3-163">Executa uma consulta do Hive contra Olá sqlContext.</span><span class="sxs-lookup"><span data-stu-id="966c3-163">Executes a Hive query against hello sqlContext.</span></span> <span data-ttu-id="966c3-164">Se hello `-o` parâmetro é transmitido, Olá resultado de Olá consulta é continuado no Olá % % contexto de Python local como uma [Pandas](http://pandas.pydata.org/) dataframe.</span><span class="sxs-lookup"><span data-stu-id="966c3-164">If hello `-o` parameter is passed, hello result of hello query is persisted in hello %%local Python context as a [Pandas](http://pandas.pydata.org/) dataframe.</span></span> |
   | <span data-ttu-id="966c3-165">local</span><span class="sxs-lookup"><span data-stu-id="966c3-165">local</span></span> |`%%local`<br>`a=1` |<span data-ttu-id="966c3-166">Todo o código de Olá linhas subsequentes é executado localmente.</span><span class="sxs-lookup"><span data-stu-id="966c3-166">All hello code in subsequent lines is executed locally.</span></span> <span data-ttu-id="966c3-167">Código tem de ser válido Python2 código mesmo independentemente kernel Olá que estiver a utilizar.</span><span class="sxs-lookup"><span data-stu-id="966c3-167">Code must be valid Python2 code even irrespective of hello kernel you are using.</span></span> <span data-ttu-id="966c3-168">Sim, mesmo se tiver selecionado **PySpark3** ou **Spark** kernels ao criar o bloco de notas Olá, se utilizar Olá `%%local` mágica numa célula, nessa célula só podem ter código Python2 válido...</span><span class="sxs-lookup"><span data-stu-id="966c3-168">So, even if you selected **PySpark3** or **Spark** kernels while creating hello notebook, if you use hello `%%local` magic in a cell, that cell must only have valid Python2 code..</span></span> |
   | <span data-ttu-id="966c3-169">registos</span><span class="sxs-lookup"><span data-stu-id="966c3-169">logs</span></span> |`%%logs` |<span data-ttu-id="966c3-170">Saídas hello registos para a sessão de Livy atual Olá.</span><span class="sxs-lookup"><span data-stu-id="966c3-170">Outputs hello logs for hello current Livy session.</span></span> |
   | <span data-ttu-id="966c3-171">eliminar</span><span class="sxs-lookup"><span data-stu-id="966c3-171">delete</span></span> |`%%delete -f -s <session number>` |<span data-ttu-id="966c3-172">Elimina uma sessão do ponto final de Livy atual Olá específica.</span><span class="sxs-lookup"><span data-stu-id="966c3-172">Deletes a specific session of hello current Livy endpoint.</span></span> <span data-ttu-id="966c3-173">Tenha em atenção que não é possível eliminar a sessão de Olá iniciada para o kernel Olá próprio.</span><span class="sxs-lookup"><span data-stu-id="966c3-173">Note that you cannot delete hello session that is initiated for hello kernel itself.</span></span> |
   | <span data-ttu-id="966c3-174">Limpeza</span><span class="sxs-lookup"><span data-stu-id="966c3-174">cleanup</span></span> |`%%cleanup -f` |<span data-ttu-id="966c3-175">Elimina todas as sessões de Olá Olá atual Livy ponto final, incluindo sessão este bloco de notas.</span><span class="sxs-lookup"><span data-stu-id="966c3-175">Deletes all hello sessions for hello current Livy endpoint, including this notebook's session.</span></span> <span data-ttu-id="966c3-176">imposição de Olá sinalizador -f é obrigatório.</span><span class="sxs-lookup"><span data-stu-id="966c3-176">hello force flag -f is mandatory.</span></span> |

   > [!NOTE]
   > <span data-ttu-id="966c3-177">Além disso toohello magia adicionado pelo kernel do PySpark Olá, também pode utilizar Olá [incorporada IPython magia](https://ipython.org/ipython-doc/3/interactive/magics.html#cell-magics), incluindo `%%sh`.</span><span class="sxs-lookup"><span data-stu-id="966c3-177">In addition toohello magics added by hello PySpark kernel, you can also use hello [built-in IPython magics](https://ipython.org/ipython-doc/3/interactive/magics.html#cell-magics), including `%%sh`.</span></span> <span data-ttu-id="966c3-178">Pode utilizar Olá `%%sh` mágica toorun scripts e bloco de código no Olá headnode de cluster.</span><span class="sxs-lookup"><span data-stu-id="966c3-178">You can use hello `%%sh` magic toorun scripts and block of code on hello cluster headnode.</span></span>
   >
   >
2. <span data-ttu-id="966c3-179">**Auto visualização**.</span><span class="sxs-lookup"><span data-stu-id="966c3-179">**Auto visualization**.</span></span> <span data-ttu-id="966c3-180">Olá **Pyspark** kernel automaticamente visualiza saída Olá de consultas do Hive e do SQL Server.</span><span class="sxs-lookup"><span data-stu-id="966c3-180">hello **Pyspark** kernel automatically visualizes hello output of Hive and SQL queries.</span></span> <span data-ttu-id="966c3-181">Pode escolher entre vários tipos diferentes de visualizações incluindo tabela circular, linha, área, a barra.</span><span class="sxs-lookup"><span data-stu-id="966c3-181">You can choose between several different types of visualizations including Table, Pie, Line, Area, Bar.</span></span>

## <a name="parameters-supported-with-hello-sql-magic"></a><span data-ttu-id="966c3-182">Parâmetros suportados com Olá % % magic de sql</span><span class="sxs-lookup"><span data-stu-id="966c3-182">Parameters supported with hello %%sql magic</span></span>
<span data-ttu-id="966c3-183">Olá `%%sql` magic suporta diferentes parâmetros que pode utilizar o tipo de Olá toocontrol de saída que recebe quando executar consultas.</span><span class="sxs-lookup"><span data-stu-id="966c3-183">hello `%%sql` magic supports different parameters that you can use toocontrol hello kind of output that you receive when you run queries.</span></span> <span data-ttu-id="966c3-184">Olá, a tabela seguinte apresenta uma lista de saída de Olá.</span><span class="sxs-lookup"><span data-stu-id="966c3-184">hello following table lists hello output.</span></span>

| <span data-ttu-id="966c3-185">Parâmetro</span><span class="sxs-lookup"><span data-stu-id="966c3-185">Parameter</span></span> | <span data-ttu-id="966c3-186">Exemplo</span><span class="sxs-lookup"><span data-stu-id="966c3-186">Example</span></span> | <span data-ttu-id="966c3-187">Descrição</span><span class="sxs-lookup"><span data-stu-id="966c3-187">Description</span></span> |
| --- | --- | --- |
| <span data-ttu-id="966c3-188">-o</span><span class="sxs-lookup"><span data-stu-id="966c3-188">-o</span></span> |`-o <VARIABLE NAME>` |<span data-ttu-id="966c3-189">Utilize este parâmetro toopersist Olá resultado de Olá consulta, Olá % % contexto de Python local, como um [Pandas](http://pandas.pydata.org/) dataframe.</span><span class="sxs-lookup"><span data-stu-id="966c3-189">Use this parameter toopersist hello result of hello query, in hello %%local Python context, as a [Pandas](http://pandas.pydata.org/) dataframe.</span></span> <span data-ttu-id="966c3-190">Olá o nome da variável de dataframe Olá é o nome da variável Olá que especificar.</span><span class="sxs-lookup"><span data-stu-id="966c3-190">hello name of hello dataframe variable is hello variable name you specify.</span></span> |
| <span data-ttu-id="966c3-191">-q</span><span class="sxs-lookup"><span data-stu-id="966c3-191">-q</span></span> |`-q` |<span data-ttu-id="966c3-192">Utilize este tooturn desativar visualizações para célula Olá.</span><span class="sxs-lookup"><span data-stu-id="966c3-192">Use this tooturn off visualizations for hello cell.</span></span> <span data-ttu-id="966c3-193">Se não quiser tooauto-visualizar conteúdo Olá de uma célula e deseje toocapture-o como um dataframe, em seguida, utilize `-q -o <VARIABLE>`.</span><span class="sxs-lookup"><span data-stu-id="966c3-193">If you don't want tooauto-visualize hello content of a cell and just want toocapture it as a dataframe, then use `-q -o <VARIABLE>`.</span></span> <span data-ttu-id="966c3-194">Se quiser tooturn desativar visualizações sem capturar resultados Olá (por exemplo, para executar uma consulta SQL, como um `CREATE TABLE` instrução), utilize `-q` sem especificar um `-o` argumento.</span><span class="sxs-lookup"><span data-stu-id="966c3-194">If you want tooturn off visualizations without capturing hello results (for example, for running a SQL query, like a `CREATE TABLE` statement), use `-q` without specifying a `-o` argument.</span></span> |
| <span data-ttu-id="966c3-195">-m</span><span class="sxs-lookup"><span data-stu-id="966c3-195">-m</span></span> |`-m <METHOD>` |<span data-ttu-id="966c3-196">Onde **método** está **demorar** ou **exemplo** (predefinição é **demorar**).</span><span class="sxs-lookup"><span data-stu-id="966c3-196">Where **METHOD** is either **take** or **sample** (default is **take**).</span></span> <span data-ttu-id="966c3-197">Se o método de Olá **demorar**, kernel Olá escolhe elementos de Olá parte superior do conjunto de dados de resultados de Olá especificado pelo MAXROWS (descrito mais à frente nesta tabela).</span><span class="sxs-lookup"><span data-stu-id="966c3-197">If hello method is **take**, hello kernel picks elements from hello top of hello result data set specified by MAXROWS (described later in this table).</span></span> <span data-ttu-id="966c3-198">Se o método de Olá **exemplo**, kernel Olá aleatoriamente amostras de elementos de conjunto de dados de Olá demasiado de acordo com`-r` parâmetro, descrito a seguir nesta tabela.</span><span class="sxs-lookup"><span data-stu-id="966c3-198">If hello method is **sample**, hello kernel randomly samples elements of hello data set according too`-r` parameter, described next in this table.</span></span> |
| <span data-ttu-id="966c3-199">-r</span><span class="sxs-lookup"><span data-stu-id="966c3-199">-r</span></span> |`-r <FRACTION>` |<span data-ttu-id="966c3-200">Aqui **FRAÇÃO** é um número de vírgula flutuante entre 0,0 e 1,0.</span><span class="sxs-lookup"><span data-stu-id="966c3-200">Here **FRACTION** is a floating-point number between 0.0 and 1.0.</span></span> <span data-ttu-id="966c3-201">Se o método de exemplo de Olá para consulta SQL Olá é `sample`, então kernel Olá aleatoriamente amostras fração de especificado Olá dos elementos de Olá do resultado de Olá definido para si.</span><span class="sxs-lookup"><span data-stu-id="966c3-201">If hello sample method for hello SQL query is `sample`, then hello kernel randomly samples hello specified fraction of hello elements of hello result set for you.</span></span> <span data-ttu-id="966c3-202">Por exemplo, se executar uma consulta SQL com argumentos de Olá `-m sample -r 0.01`, em seguida, 1 a % de linhas de resultado Olá aleatoriamente servem como amostra.</span><span class="sxs-lookup"><span data-stu-id="966c3-202">For example, if you run a SQL query with hello arguments `-m sample -r 0.01`, then 1% of hello result rows are randomly sampled.</span></span> |
| -n |`-n <MAXROWS>` |<span data-ttu-id="966c3-203">**MAXROWS** é um valor de número inteiro.</span><span class="sxs-lookup"><span data-stu-id="966c3-203">**MAXROWS** is an integer value.</span></span> <span data-ttu-id="966c3-204">kernel Olá limita Olá número de linhas de saída demasiado**MAXROWS**.</span><span class="sxs-lookup"><span data-stu-id="966c3-204">hello kernel limits hello number of output rows too**MAXROWS**.</span></span> <span data-ttu-id="966c3-205">Se **MAXROWS** é como um número negativo **-1**, em seguida, Olá número de linhas no conjunto de resultados de Olá não é limitado.</span><span class="sxs-lookup"><span data-stu-id="966c3-205">If **MAXROWS** is a negative number such as **-1**, then hello number of rows in hello result set is not limited.</span></span> |

<span data-ttu-id="966c3-206">**Exemplo:**</span><span class="sxs-lookup"><span data-stu-id="966c3-206">**Example:**</span></span>

    %%sql -q -m sample -r 0.1 -n 500 -o query2
    SELECT * FROM hivesampletable

<span data-ttu-id="966c3-207">declaração de Olá acima Olá seguintes:</span><span class="sxs-lookup"><span data-stu-id="966c3-207">hello statement above does hello following:</span></span>

* <span data-ttu-id="966c3-208">Seleciona todos os registos da **hivesampletable**.</span><span class="sxs-lookup"><span data-stu-id="966c3-208">Selects all records from **hivesampletable**.</span></span>
* <span data-ttu-id="966c3-209">Uma vez que utilizamos - q, desligar automaticamente visualização.</span><span class="sxs-lookup"><span data-stu-id="966c3-209">Because we use -q, it turns off auto-visualization.</span></span>
* <span data-ttu-id="966c3-210">Uma vez que utilizamos `-m sample -r 0.1 -n 500` aleatoriamente de exemplo 10% de linhas Olá Olá hivesampletable e Olá, limites de tamanho de Olá resultado conjunto too500 linhas.</span><span class="sxs-lookup"><span data-stu-id="966c3-210">Because we use `-m sample -r 0.1 -n 500` it randomly samples 10% of hello rows in hello hivesampletable and limits hello size of hello result set too500 rows.</span></span>
* <span data-ttu-id="966c3-211">Por fim, porque é utilizado `-o query2` também economizam saída Olá para um dataframe chamado **query2**.</span><span class="sxs-lookup"><span data-stu-id="966c3-211">Finally, because we used `-o query2` it also saves hello output into a dataframe called **query2**.</span></span>

## <a name="considerations-while-using-hello-new-kernels"></a><span data-ttu-id="966c3-212">Considerações ao utilizar Olá kernels novo</span><span class="sxs-lookup"><span data-stu-id="966c3-212">Considerations while using hello new kernels</span></span>

<span data-ttu-id="966c3-213">Qualquer kernel utilizar, deixar os blocos de notas Olá executar consome recursos do cluster Olá.</span><span class="sxs-lookup"><span data-stu-id="966c3-213">Whichever kernel you use, leaving hello notebooks running consumes hello cluster resources.</span></span>  <span data-ttu-id="966c3-214">Com estas kernels porque contextos de Olá são a configuração predefinidos, basta sair blocos de notas Olá não kill contexto Olá e, por conseguinte, os recursos do cluster Olá continuar toobe em utilização.</span><span class="sxs-lookup"><span data-stu-id="966c3-214">With these kernels, because hello contexts are preset, simply exiting hello notebooks does not kill hello context and hence hello cluster resources continue toobe in use.</span></span> <span data-ttu-id="966c3-215">Uma boa prática é toouse Olá **fechar e parar** opção a partir do bloco de notas de Olá **ficheiro** menu quando tiver terminado de utilizar o bloco de notas Olá, que inutilizam contexto Olá e, em seguida, sai Olá bloco de notas.</span><span class="sxs-lookup"><span data-stu-id="966c3-215">A good practice is toouse hello **Close and Halt** option from hello notebook's **File** menu when you are finished using hello notebook, which kills hello context and then exits hello notebook.</span></span>     

## <a name="show-me-some-examples"></a><span data-ttu-id="966c3-216">Mostrar alguns exemplos</span><span class="sxs-lookup"><span data-stu-id="966c3-216">Show me some examples</span></span>

<span data-ttu-id="966c3-217">Quando abre um bloco de notas do Jupyter, verá duas pastas disponíveis no nível de raiz de Olá.</span><span class="sxs-lookup"><span data-stu-id="966c3-217">When you open a Jupyter notebook, you see two folders available at hello root level.</span></span>

* <span data-ttu-id="966c3-218">Olá **PySpark** pasta tem blocos de notas do exemplo Olá que utilize novo **Python** kernel.</span><span class="sxs-lookup"><span data-stu-id="966c3-218">hello **PySpark** folder has sample notebooks that use hello new **Python** kernel.</span></span>
* <span data-ttu-id="966c3-219">Olá **Scala** pasta tem blocos de notas do exemplo Olá que utilize novo **Spark** kernel.</span><span class="sxs-lookup"><span data-stu-id="966c3-219">hello **Scala** folder has sample notebooks that use hello new **Spark** kernel.</span></span>

<span data-ttu-id="966c3-220">Pode abrir Olá **00 - [leia-ME primeiro] funcionalidades de Kernel do Spark Magic** bloco de notas do Olá **PySpark** ou **Spark** toolearn pasta sobre a magia diferentes Olá disponíveis.</span><span class="sxs-lookup"><span data-stu-id="966c3-220">You can open hello **00 - [READ ME FIRST] Spark Magic Kernel Features** notebook from hello **PySpark** or **Spark** folder toolearn about hello different magics available.</span></span> <span data-ttu-id="966c3-221">Também pode utilizar Olá outros blocos de notas do exemplo disponíveis em Olá duas pastas toolearn como tooachieve diferentes cenários de utilização de blocos de notas do Jupyter com clusters do HDInsight Spark.</span><span class="sxs-lookup"><span data-stu-id="966c3-221">You can also use hello other sample notebooks available under hello two folders toolearn how tooachieve different scenarios using Jupyter notebooks with HDInsight Spark clusters.</span></span>

## <a name="where-are-hello-notebooks-stored"></a><span data-ttu-id="966c3-222">Onde estão armazenados os blocos de notas Olá?</span><span class="sxs-lookup"><span data-stu-id="966c3-222">Where are hello notebooks stored?</span></span>

<span data-ttu-id="966c3-223">Blocos de notas do Jupyter são guardados toohello conta de armazenamento associada ao cluster Olá em Olá **/HdiNotebooks** pasta.</span><span class="sxs-lookup"><span data-stu-id="966c3-223">Jupyter notebooks are saved toohello storage account associated with hello cluster under hello **/HdiNotebooks** folder.</span></span>  <span data-ttu-id="966c3-224">Blocos de notas, ficheiros de texto e pastas que criar a partir de dentro do Jupyter são acessíveis a partir da conta de armazenamento Olá.</span><span class="sxs-lookup"><span data-stu-id="966c3-224">Notebooks, text files, and folders that you create from within Jupyter are accessible from hello storage account.</span></span>  <span data-ttu-id="966c3-225">Por exemplo, se utilizar o Jupyter toocreate uma pasta **myfolder** e um bloco de notas **myfolder/mynotebook.ipynb**, pode aceder nesse bloco de notas em `/HdiNotebooks/myfolder/mynotebook.ipynb` na conta do storage Olá.</span><span class="sxs-lookup"><span data-stu-id="966c3-225">For example, if you use Jupyter toocreate a folder **myfolder** and a notebook **myfolder/mynotebook.ipynb**, you can access that notebook at `/HdiNotebooks/myfolder/mynotebook.ipynb` within hello storage account.</span></span>  <span data-ttu-id="966c3-226">Olá inversa também se aplica, ou seja, se carregar um bloco de notas diretamente a conta de armazenamento tooyour em `/HdiNotebooks/mynotebook1.ipynb`, o bloco de notas do Olá é também visível a partir do Jupyter.</span><span class="sxs-lookup"><span data-stu-id="966c3-226">hello reverse is also true, that is, if you upload a notebook directly tooyour storage account at `/HdiNotebooks/mynotebook1.ipynb`, hello notebook is visible from Jupyter as well.</span></span>  <span data-ttu-id="966c3-227">Blocos de notas permanecem na conta do storage Olá, mesmo depois do cluster Olá é eliminado.</span><span class="sxs-lookup"><span data-stu-id="966c3-227">Notebooks remain in hello storage account even after hello cluster is deleted.</span></span>

<span data-ttu-id="966c3-228">blocos de notas são guardados toohello conta de armazenamento de forma de Olá é compatível com HDFS.</span><span class="sxs-lookup"><span data-stu-id="966c3-228">hello way notebooks are saved toohello storage account is compatible with HDFS.</span></span> <span data-ttu-id="966c3-229">Deste modo, se lhe SSH no cluster Olá, que pode utilizar comandos de gestão de ficheiros conforme mostrado no seguinte fragmento de Olá:</span><span class="sxs-lookup"><span data-stu-id="966c3-229">So, if you SSH into hello cluster you can use file management commands as shown in hello following snippet:</span></span>

    hdfs dfs -ls /HdiNotebooks                               # List everything at hello root directory – everything in this directory is visible tooJupyter from hello home page
    hdfs dfs –copyToLocal /HdiNotebooks                    # Download hello contents of hello HdiNotebooks folder
    hdfs dfs –copyFromLocal example.ipynb /HdiNotebooks   # Upload a notebook example.ipynb toohello root folder so it’s visible from Jupyter


<span data-ttu-id="966c3-230">No caso de existirem problemas de acesso à conta de armazenamento Olá para cluster Olá, blocos de notas Olá também são guardados no Olá headnode `/var/lib/jupyter`.</span><span class="sxs-lookup"><span data-stu-id="966c3-230">In case there are issues accessing hello storage account for hello cluster, hello notebooks are also saved on hello headnode `/var/lib/jupyter`.</span></span>

## <a name="supported-browser"></a><span data-ttu-id="966c3-231">Browser suportado</span><span class="sxs-lookup"><span data-stu-id="966c3-231">Supported browser</span></span>

<span data-ttu-id="966c3-232">Blocos de notas do Jupyter nos clusters do Spark HDInsight são suportados apenas no Google Chrome.</span><span class="sxs-lookup"><span data-stu-id="966c3-232">Jupyter notebooks on Spark HDInsight clusters are supported only on Google Chrome.</span></span>

## <a name="feedback"></a><span data-ttu-id="966c3-233">Comentários</span><span class="sxs-lookup"><span data-stu-id="966c3-233">Feedback</span></span>
<span data-ttu-id="966c3-234">kernels novo Olá estão em fase de evolução e serão madura ao longo do tempo.</span><span class="sxs-lookup"><span data-stu-id="966c3-234">hello new kernels are in evolving stage and will mature over time.</span></span> <span data-ttu-id="966c3-235">Isto pode significar que APIs alterar como estes kernels madura.</span><span class="sxs-lookup"><span data-stu-id="966c3-235">This could also mean that APIs could change as these kernels mature.</span></span> <span data-ttu-id="966c3-236">Agradecemos quaisquer comentários que tenham ao utilizar estas kernels de novo.</span><span class="sxs-lookup"><span data-stu-id="966c3-236">We would appreciate any feedback that you have while using these new kernels.</span></span> <span data-ttu-id="966c3-237">Isto é útil em formação de versão final do Olá destes kernels.</span><span class="sxs-lookup"><span data-stu-id="966c3-237">This is useful in shaping hello final release of these kernels.</span></span> <span data-ttu-id="966c3-238">Pode deixar os seus comentários comentários em Olá **comentários** secção na parte inferior de Olá deste artigo.</span><span class="sxs-lookup"><span data-stu-id="966c3-238">You can leave your comments/feedback under hello **Comments** section at hello bottom of this article.</span></span>

## <span data-ttu-id="966c3-239"><a name="seealso"></a>Ver também</span><span class="sxs-lookup"><span data-stu-id="966c3-239"><a name="seealso"></a>See also</span></span>
* [<span data-ttu-id="966c3-240">Descrição geral: Apache Spark no Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="966c3-240">Overview: Apache Spark on Azure HDInsight</span></span>](hdinsight-apache-spark-overview.md)

### <a name="scenarios"></a><span data-ttu-id="966c3-241">Cenários</span><span class="sxs-lookup"><span data-stu-id="966c3-241">Scenarios</span></span>
* [<span data-ttu-id="966c3-242">Spark com BI: Efetuar uma análise de dados interativa com o Spark no HDInsight com ferramentas do BI</span><span class="sxs-lookup"><span data-stu-id="966c3-242">Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools</span></span>](hdinsight-apache-spark-use-bi-tools.md)
* [<span data-ttu-id="966c3-243">Spark com Machine Learning: Utilizar o Spark no HDInsight para analisar a temperatura do edifício com dados de AVAC</span><span class="sxs-lookup"><span data-stu-id="966c3-243">Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)
* [<span data-ttu-id="966c3-244">Spark com Machine Learning: utilizar o Spark no HDInsight toopredict inspeções alimentares</span><span class="sxs-lookup"><span data-stu-id="966c3-244">Spark with Machine Learning: Use Spark in HDInsight toopredict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)
* [<span data-ttu-id="966c3-245">Transmissão em Fluxo do Spark: Utilizar o Spark no HDInsight para criar aplicações de transmissão em fluxo em tempo real</span><span class="sxs-lookup"><span data-stu-id="966c3-245">Spark Streaming: Use Spark in HDInsight for building real-time streaming applications</span></span>](hdinsight-apache-spark-eventhub-streaming.md)
* [<span data-ttu-id="966c3-246">Análise de registos de sites com o Spark no HDInsight</span><span class="sxs-lookup"><span data-stu-id="966c3-246">Website log analysis using Spark in HDInsight</span></span>](hdinsight-apache-spark-custom-library-website-log-analysis.md)

### <a name="create-and-run-applications"></a><span data-ttu-id="966c3-247">Criar e executar aplicações</span><span class="sxs-lookup"><span data-stu-id="966c3-247">Create and run applications</span></span>
* [<span data-ttu-id="966c3-248">Criar uma aplicação autónoma com o Scala</span><span class="sxs-lookup"><span data-stu-id="966c3-248">Create a standalone application using Scala</span></span>](hdinsight-apache-spark-create-standalone-application.md)
* [<span data-ttu-id="966c3-249">Executar tarefas remotamente num cluster do Spark com o Livy</span><span class="sxs-lookup"><span data-stu-id="966c3-249">Run jobs remotely on a Spark cluster using Livy</span></span>](hdinsight-apache-spark-livy-rest-interface.md)

### <a name="tools-and-extensions"></a><span data-ttu-id="966c3-250">Ferramentas e extensões</span><span class="sxs-lookup"><span data-stu-id="966c3-250">Tools and extensions</span></span>
* [<span data-ttu-id="966c3-251">Utilizar o plug-in ferramentas do HDInsight para o IntelliJ IDEA toocreate e submeter aplicações do Spark Scala</span><span class="sxs-lookup"><span data-stu-id="966c3-251">Use HDInsight Tools Plugin for IntelliJ IDEA toocreate and submit Spark Scala applications</span></span>](hdinsight-apache-spark-intellij-tool-plugin.md)
* [<span data-ttu-id="966c3-252">Utilizar o plug-in ferramentas do HDInsight para aplicações do Spark IntelliJ IDEA toodebug remotamente</span><span class="sxs-lookup"><span data-stu-id="966c3-252">Use HDInsight Tools Plugin for IntelliJ IDEA toodebug Spark applications remotely</span></span>](hdinsight-apache-spark-intellij-tool-plugin-debug-jobs-remotely.md)
* [<span data-ttu-id="966c3-253">Utilizar blocos de notas do Zeppelin com um cluster do Spark no HDInsight</span><span class="sxs-lookup"><span data-stu-id="966c3-253">Use Zeppelin notebooks with a Spark cluster on HDInsight</span></span>](hdinsight-apache-spark-zeppelin-notebook.md)
* [<span data-ttu-id="966c3-254">Utilizar pacotes externos com blocos de notas do Jupyter</span><span class="sxs-lookup"><span data-stu-id="966c3-254">Use external packages with Jupyter notebooks</span></span>](hdinsight-apache-spark-jupyter-notebook-use-external-packages.md)
* [<span data-ttu-id="966c3-255">Instalar o Jupyter no seu computador e ligue tooan cluster do HDInsight Spark</span><span class="sxs-lookup"><span data-stu-id="966c3-255">Install Jupyter on your computer and connect tooan HDInsight Spark cluster</span></span>](hdinsight-apache-spark-jupyter-notebook-install-locally.md)

### <a name="manage-resources"></a><span data-ttu-id="966c3-256">Gerir recursos</span><span class="sxs-lookup"><span data-stu-id="966c3-256">Manage resources</span></span>
* [<span data-ttu-id="966c3-257">Gerir os recursos de cluster do Apache Spark Olá no Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="966c3-257">Manage resources for hello Apache Spark cluster in Azure HDInsight</span></span>](hdinsight-apache-spark-resource-manager.md)
* [<span data-ttu-id="966c3-258">Controlar e depurar tarefas em execução num cluster do Apache Spark do HDInsight</span><span class="sxs-lookup"><span data-stu-id="966c3-258">Track and debug jobs running on an Apache Spark cluster in HDInsight</span></span>](hdinsight-apache-spark-job-debugging.md)
