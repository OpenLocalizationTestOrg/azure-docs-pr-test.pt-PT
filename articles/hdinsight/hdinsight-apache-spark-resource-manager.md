---
title: cluster de recursos de aaaManage para Apache Spark no Azure HDInsight | Microsoft Docs
description: Saiba como toouse gerir os recursos de clusters do Spark no Azure HDInsight para um melhor desempenho.
services: hdinsight
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: 9da7d4e3-458e-4296-a628-77b14643f7e4
ms.service: hdinsight
ms.custom: hdinsightactive
ms.workload: big-data
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 07/21/2017
ms.author: nitinme
ms.openlocfilehash: e18682a24f77494db884105f9db03c0a350ddad6
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: pt-PT
ms.lasthandoff: 10/06/2017
---
# <a name="manage-resources-for-apache-spark-cluster-on-azure-hdinsight"></a><span data-ttu-id="fc112-103">Gerir os recursos de cluster do Apache Spark no Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="fc112-103">Manage resources for Apache Spark cluster on Azure HDInsight</span></span> 

<span data-ttu-id="fc112-104">Neste artigo, ficará a saber como associados a interfaces de Olá tooaccess como Ambari IU, IU do YARN e Olá Spark histórico de servidor com o cluster do Spark.</span><span class="sxs-lookup"><span data-stu-id="fc112-104">In this article you will learn how tooaccess hello interfaces like Ambari UI, YARN UI, and hello Spark History Server associated with your Spark cluster.</span></span> <span data-ttu-id="fc112-105">Também ficará a saber sobre como tootune Olá configuração de cluster para um desempenho ideal.</span><span class="sxs-lookup"><span data-stu-id="fc112-105">You will also learn about how tootune hello cluster configuration for optimal performance.</span></span>

<span data-ttu-id="fc112-106">**Pré-requisitos:**</span><span class="sxs-lookup"><span data-stu-id="fc112-106">**Prerequisites:**</span></span>

<span data-ttu-id="fc112-107">Tem de ter o seguinte Olá:</span><span class="sxs-lookup"><span data-stu-id="fc112-107">You must have hello following:</span></span>

* <span data-ttu-id="fc112-108">Uma subscrição do Azure.</span><span class="sxs-lookup"><span data-stu-id="fc112-108">An Azure subscription.</span></span> <span data-ttu-id="fc112-109">Consulte [Obter uma avaliação gratuita do Azure](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span><span class="sxs-lookup"><span data-stu-id="fc112-109">See [Get Azure free trial](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span></span>
* <span data-ttu-id="fc112-110">Um cluster do Apache Spark no HDInsight.</span><span class="sxs-lookup"><span data-stu-id="fc112-110">An Apache Spark cluster on HDInsight.</span></span> <span data-ttu-id="fc112-111">Para obter instruções, consulte [clusters do Apache Spark criar no Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="fc112-111">For instructions, see [Create Apache Spark clusters in Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span>

## <a name="how-do-i-launch-hello-ambari-web-ui"></a><span data-ttu-id="fc112-112">Como iniciar o Olá IU da Web do Ambari</span><span class="sxs-lookup"><span data-stu-id="fc112-112">How do I launch hello Ambari Web UI?</span></span>
1. <span data-ttu-id="fc112-113">De Olá [Portal do Azure](https://portal.azure.com/), de Olá startboard, clique no mosaico Olá para o cluster do Spark (se o tiver afixado toohello startboard).</span><span class="sxs-lookup"><span data-stu-id="fc112-113">From hello [Azure Portal](https://portal.azure.com/), from hello startboard, click hello tile for your Spark cluster (if you pinned it toohello startboard).</span></span> <span data-ttu-id="fc112-114">Também pode navegar tooyour cluster em **Procurar tudo** > **Clusters do HDInsight**.</span><span class="sxs-lookup"><span data-stu-id="fc112-114">You can also navigate tooyour cluster under **Browse All** > **HDInsight Clusters**.</span></span>
2. <span data-ttu-id="fc112-115">No painel de cluster do Spark de Olá, clique em **Dashboard**.</span><span class="sxs-lookup"><span data-stu-id="fc112-115">From hello Spark cluster blade, click **Dashboard**.</span></span> <span data-ttu-id="fc112-116">Quando lhe for pedido, introduza as credenciais de administrador Olá para um cluster do Spark Olá.</span><span class="sxs-lookup"><span data-stu-id="fc112-116">When prompted, enter hello admin credentials for hello Spark cluster.</span></span>

    <span data-ttu-id="fc112-117">![Inicie o Ambari](./media/hdinsight-apache-spark-resource-manager/hdinsight-launch-cluster-dashboard.png "inicie o Gestor de recursos")</span><span class="sxs-lookup"><span data-stu-id="fc112-117">![Launch Ambari](./media/hdinsight-apache-spark-resource-manager/hdinsight-launch-cluster-dashboard.png "Start Resource Manager")</span></span>
3. <span data-ttu-id="fc112-118">Isto deve iniciar Olá IU da Web do Ambari, conforme mostrado abaixo.</span><span class="sxs-lookup"><span data-stu-id="fc112-118">This should launch hello Ambari Web UI, as shown below.</span></span>

    <span data-ttu-id="fc112-119">![IU da Web do Ambari](./media/hdinsight-apache-spark-resource-manager/ambari-web-ui.png "IU da Web do Ambari")</span><span class="sxs-lookup"><span data-stu-id="fc112-119">![Ambari Web UI](./media/hdinsight-apache-spark-resource-manager/ambari-web-ui.png "Ambari Web UI")</span></span>   

## <a name="how-do-i-launch-hello-spark-history-server"></a><span data-ttu-id="fc112-120">Como iniciar o Olá Spark histórico de servidor</span><span class="sxs-lookup"><span data-stu-id="fc112-120">How do I launch hello Spark History Server?</span></span>
1. <span data-ttu-id="fc112-121">De Olá [Portal do Azure](https://portal.azure.com/), de Olá startboard, clique no mosaico Olá para o cluster do Spark (se o tiver afixado toohello startboard).</span><span class="sxs-lookup"><span data-stu-id="fc112-121">From hello [Azure Portal](https://portal.azure.com/), from hello startboard, click hello tile for your Spark cluster (if you pinned it toohello startboard).</span></span>
2. <span data-ttu-id="fc112-122">De Olá cluster painel, em **ligações rápidas**, clique em **Cluster Dashboard**.</span><span class="sxs-lookup"><span data-stu-id="fc112-122">From hello cluster blade, under **Quick Links**, click **Cluster Dashboard**.</span></span> <span data-ttu-id="fc112-123">No Olá **Cluster Dashboard** painel, clique em **Spark histórico servidor**.</span><span class="sxs-lookup"><span data-stu-id="fc112-123">In hello **Cluster Dashboard** blade, click **Spark History Server**.</span></span>

    <span data-ttu-id="fc112-124">![Servidor do histórico de spark](./media/hdinsight-apache-spark-resource-manager/launch-history-server.png "Spark histórico servidor")</span><span class="sxs-lookup"><span data-stu-id="fc112-124">![Spark History Server](./media/hdinsight-apache-spark-resource-manager/launch-history-server.png "Spark History Server")</span></span>

    <span data-ttu-id="fc112-125">Quando lhe for pedido, introduza as credenciais de administrador Olá para um cluster do Spark Olá.</span><span class="sxs-lookup"><span data-stu-id="fc112-125">When prompted, enter hello admin credentials for hello Spark cluster.</span></span>

## <a name="how-do-i-launch-hello-yarn-ui"></a><span data-ttu-id="fc112-126">Como iniciar a IU do Yarn de Olá?</span><span class="sxs-lookup"><span data-stu-id="fc112-126">How do I launch hello Yarn UI?</span></span>
<span data-ttu-id="fc112-127">Pode utilizar Olá IU do YARN toomonitor aplicações que estão atualmente em execução no cluster do Spark Olá.</span><span class="sxs-lookup"><span data-stu-id="fc112-127">You can use hello YARN UI toomonitor applications that are currently running on hello Spark cluster.</span></span>

1. <span data-ttu-id="fc112-128">No painel do cluster de Olá, clique em **Cluster Dashboard**e, em seguida, clique em **YARN**.</span><span class="sxs-lookup"><span data-stu-id="fc112-128">From hello cluster blade, click **Cluster Dashboard**, and then click **YARN**.</span></span>

    ![Iniciar a IU do YARN](./media/hdinsight-apache-spark-resource-manager/launch-yarn-ui.png)

   > [!TIP]
   > <span data-ttu-id="fc112-130">Em alternativa, pode também iniciar Olá IU do YARN de Olá IU do Ambari.</span><span class="sxs-lookup"><span data-stu-id="fc112-130">Alternatively, you can also launch hello YARN UI from hello Ambari UI.</span></span> <span data-ttu-id="fc112-131">toolaunch Olá IU do Ambari, no painel do cluster de Olá, clique em **Cluster Dashboard**e, em seguida, clique em **Dashboard de Cluster do HDInsight**.</span><span class="sxs-lookup"><span data-stu-id="fc112-131">toolaunch hello Ambari UI, from hello cluster blade, click **Cluster Dashboard**, and then click **HDInsight Cluster Dashboard**.</span></span> <span data-ttu-id="fc112-132">Na IU do Ambari Olá, clique em **YARN**, clique em **ligações rápidas**, clique em Gestor de recursos do Active Directory Olá e, em seguida, clique em **ResourceManager IU**.</span><span class="sxs-lookup"><span data-stu-id="fc112-132">From hello Ambari UI, click **YARN**, click **Quick Links**, click hello active resource manager, and then click **ResourceManager UI**.</span></span>
   >
   >

## <a name="what-is-hello-optimum-cluster-configuration-toorun-spark-applications"></a><span data-ttu-id="fc112-133">O que é aplicações do Spark toorun Olá cluster ideal configuração?</span><span class="sxs-lookup"><span data-stu-id="fc112-133">What is hello optimum cluster configuration toorun Spark applications?</span></span>
<span data-ttu-id="fc112-134">os parâmetros de chave de Olá três que podem ser utilizados para a configuração de Spark consoante os requisitos da aplicação são `spark.executor.instances`, `spark.executor.cores`, e `spark.executor.memory`.</span><span class="sxs-lookup"><span data-stu-id="fc112-134">hello three key parameters that can be used for Spark configuration depending on application requirements are `spark.executor.instances`, `spark.executor.cores`, and `spark.executor.memory`.</span></span> <span data-ttu-id="fc112-135">Um Executor é um processo iniciado para uma aplicação de Spark.</span><span class="sxs-lookup"><span data-stu-id="fc112-135">An Executor is a process launched for a Spark application.</span></span> <span data-ttu-id="fc112-136">Este é executado no nó de trabalho de Olá e é responsável toocarry tarefas Olá para aplicação Olá.</span><span class="sxs-lookup"><span data-stu-id="fc112-136">It runs on hello worker node and is responsible toocarry out hello tasks for hello application.</span></span> <span data-ttu-id="fc112-137">Olá predefinição o número de executor e tamanhos de executor de Olá para cada cluster é calculado com base no número de Olá de nós de trabalho e o tamanho de nó de trabalho de Olá.</span><span class="sxs-lookup"><span data-stu-id="fc112-137">hello default number of executors and hello executor sizes for each cluster is calculated based on hello number of worker nodes and hello worker node size.</span></span> <span data-ttu-id="fc112-138">Estes são armazenados no `spark-defaults.conf` em nós principais do cluster Olá.</span><span class="sxs-lookup"><span data-stu-id="fc112-138">These are stored in `spark-defaults.conf` on hello cluster head nodes.</span></span>

<span data-ttu-id="fc112-139">parâmetros de configuração de três Olá podem ser configurados ao nível do cluster Olá (para todas as aplicações que são executadas no cluster de Olá) ou podem ser especificados para cada aplicação individuais bem.</span><span class="sxs-lookup"><span data-stu-id="fc112-139">hello three configuration parameters can be configured at hello cluster level (for all applications that run on hello cluster) or can be specified for each individual application as well.</span></span>

### <a name="change-hello-parameters-using-ambari-ui"></a><span data-ttu-id="fc112-140">Altere os parâmetros de Olá utilizando a IU do Ambari</span><span class="sxs-lookup"><span data-stu-id="fc112-140">Change hello parameters using Ambari UI</span></span>
1. <span data-ttu-id="fc112-141">No Olá Ambari IU clique **Spark**, clique em **folhas**e, em seguida, expanda **personalizada spark-predefinições**.</span><span class="sxs-lookup"><span data-stu-id="fc112-141">From hello Ambari UI click **Spark**, click **Configs**, and then expand **Custom spark-defaults**.</span></span>

    ![Parâmetros de conjunto com o Ambari](./media/hdinsight-apache-spark-resource-manager/set-parameters-using-ambari.png)
2. <span data-ttu-id="fc112-143">os valores predefinidos de Olá são executadas em simultâneo no cluster de Olá de aplicações do Spark toohave boa 4.</span><span class="sxs-lookup"><span data-stu-id="fc112-143">hello default values are good toohave 4 Spark applications run concurrently on hello cluster.</span></span> <span data-ttu-id="fc112-144">Pode alterações estes valores na interface de utilizador de Olá, conforme mostrado abaixo.</span><span class="sxs-lookup"><span data-stu-id="fc112-144">You can changes these values from hello user interface, as shown below.</span></span>

    ![Parâmetros de conjunto com o Ambari](./media/hdinsight-apache-spark-resource-manager/set-executor-parameters.png)
3. <span data-ttu-id="fc112-146">Clique em **guardar** alterações de configuração de Olá toosave.</span><span class="sxs-lookup"><span data-stu-id="fc112-146">Click **Save** toosave hello configuration changes.</span></span> <span data-ttu-id="fc112-147">Em Olá parte superior da página Olá, será solicitado toorestart Olá, todos os serviços afectados.</span><span class="sxs-lookup"><span data-stu-id="fc112-147">At hello top of hello page, you will be prompted toorestart all hello affected services.</span></span> <span data-ttu-id="fc112-148">Clique em **reiniciar**.</span><span class="sxs-lookup"><span data-stu-id="fc112-148">Click **Restart**.</span></span>

    ![Reinicie os serviços](./media/hdinsight-apache-spark-resource-manager/restart-services.png)

### <a name="change-hello-parameters-for-an-application-running-in-jupyter-notebook"></a><span data-ttu-id="fc112-150">Altere os parâmetros de Olá para uma aplicação em execução no bloco de notas do Jupyter</span><span class="sxs-lookup"><span data-stu-id="fc112-150">Change hello parameters for an application running in Jupyter notebook</span></span>
<span data-ttu-id="fc112-151">Para aplicações em execução no bloco de notas do Jupyter Olá, pode utilizar Olá `%%configure` mágica alterações de configuração de Olá toomake.</span><span class="sxs-lookup"><span data-stu-id="fc112-151">For applications running in hello Jupyter notebook, you can use hello `%%configure` magic toomake hello configuration changes.</span></span> <span data-ttu-id="fc112-152">Idealmente, tem de se essas alterações no início de Olá da aplicação Olá, antes de executar a sua primeira célula do código.</span><span class="sxs-lookup"><span data-stu-id="fc112-152">Ideally, you must make such changes at hello beginning of hello application, before you run your first code cell.</span></span> <span data-ttu-id="fc112-153">Isto garante que a configuração Olá é aplicado toohello Livy sessão, quando é criada.</span><span class="sxs-lookup"><span data-stu-id="fc112-153">This ensures that hello configuration is applied toohello Livy session, when it gets created.</span></span> <span data-ttu-id="fc112-154">Se pretender que a configuração de Olá toochange uma fase posterior na aplicação Olá, tem de utilizar Olá `-f` parâmetro.</span><span class="sxs-lookup"><span data-stu-id="fc112-154">If you want toochange hello configuration at a later stage in hello application, you must use hello `-f` parameter.</span></span> <span data-ttu-id="fc112-155">No entanto, por se o fizer, todos os progresso na Olá aplicação serão perdida.</span><span class="sxs-lookup"><span data-stu-id="fc112-155">However, by doing so all progress in hello application will be lost.</span></span>

<span data-ttu-id="fc112-156">fragmento Olá abaixo mostra como toochange Olá configuração para uma aplicação em execução no Jupyter.</span><span class="sxs-lookup"><span data-stu-id="fc112-156">hello snippet below shows how toochange hello configuration for an application running in Jupyter.</span></span>

    %%configure
    {"executorMemory": "3072M", "executorCores": 4, "numExecutors":10}

<span data-ttu-id="fc112-157">Parâmetros de configuração tem de ser transmitidos como uma cadeia JSON e tem de estar na linha seguinte Olá após magic Olá, conforme apresentado na coluna de exemplo de Olá.</span><span class="sxs-lookup"><span data-stu-id="fc112-157">Configuration parameters must be passed in as a JSON string and must be on hello next line after hello magic, as shown in hello example column.</span></span>

### <a name="change-hello-parameters-for-an-application-submitted-using-spark-submit"></a><span data-ttu-id="fc112-158">Parâmetros de Olá de alteração para uma aplicação enviados através de spark-submeter</span><span class="sxs-lookup"><span data-stu-id="fc112-158">Change hello parameters for an application submitted using spark-submit</span></span>
<span data-ttu-id="fc112-159">Os seguintes comandos é um exemplo de como toochange Olá parâmetros de configuração para uma aplicação de batch que é submetido utilizando `spark-submit`.</span><span class="sxs-lookup"><span data-stu-id="fc112-159">Following command is an example of how toochange hello configuration parameters for a batch application that is submitted using `spark-submit`.</span></span>

    spark-submit --class <hello application class tooexecute> --executor-memory 3072M --executor-cores 4 –-num-executors 10 <location of application jar file> <application parameters>

### <a name="change-hello-parameters-for-an-application-submitted-using-curl"></a><span data-ttu-id="fc112-160">Altere os parâmetros de Olá para uma aplicação submetido utilizando cURL</span><span class="sxs-lookup"><span data-stu-id="fc112-160">Change hello parameters for an application submitted using cURL</span></span>
<span data-ttu-id="fc112-161">Os seguintes comandos é um exemplo de como toochange Olá parâmetros de configuração para uma aplicação de batch que é submetido utilizando utilizando cURL.</span><span class="sxs-lookup"><span data-stu-id="fc112-161">Following command is an example of how toochange hello configuration parameters for a batch application that is submitted using using cURL.</span></span>

    curl -k -v -H 'Content-Type: application/json' -X POST -d '{"file":"<location of application jar file>", "className":"<hello application class tooexecute>", "args":[<application parameters>], "numExecutors":10, "executorMemory":"2G", "executorCores":5' localhost:8998/batches

### <a name="how-do-i-change-these-parameters-on-a-spark-thrift-server"></a><span data-ttu-id="fc112-162">Como posso alterar estes parâmetros num servidor Thrift de Spark?</span><span class="sxs-lookup"><span data-stu-id="fc112-162">How do I change these parameters on a Spark Thrift Server?</span></span>
<span data-ttu-id="fc112-163">Servidor Thrift de Spark fornece o cluster do Spark JDBC/ODBC acesso tooa e é utilizado tooservice consultas do Spark SQL.</span><span class="sxs-lookup"><span data-stu-id="fc112-163">Spark Thrift Server provides JDBC/ODBC access tooa Spark cluster and is used tooservice Spark SQL queries.</span></span> <span data-ttu-id="fc112-164">Ferramentas como o Power BI, Tableau etc.</span><span class="sxs-lookup"><span data-stu-id="fc112-164">Tools like Power BI, Tableau etc.</span></span> <span data-ttu-id="fc112-165">Utilize ODBC protocolo toocommunicate com as consultas de Spark SQL do servidor Thrift de Spark tooexecute como uma aplicação de Spark.</span><span class="sxs-lookup"><span data-stu-id="fc112-165">use ODBC protocol toocommunicate with Spark Thrift Server tooexecute Spark SQL queries as a Spark Application.</span></span> <span data-ttu-id="fc112-166">Quando é criado um cluster do Spark, duas instâncias do Olá servidor Thrift de Spark são iniciados, e um em cada nó principal.</span><span class="sxs-lookup"><span data-stu-id="fc112-166">When a Spark cluster is created, two instances of hello Spark Thrift Server are started, one on each head node.</span></span> <span data-ttu-id="fc112-167">Cada servidor Thrift de Spark é visível como uma aplicação do Spark no Olá IU do YARN.</span><span class="sxs-lookup"><span data-stu-id="fc112-167">Each Spark Thrift Server is visible as a Spark application in hello YARN UI.</span></span>

<span data-ttu-id="fc112-168">Utiliza servidor Thrift de Spark Spark alocação dinâmica executor e, por conseguinte, Olá `spark.executor.instances` não é utilizado.</span><span class="sxs-lookup"><span data-stu-id="fc112-168">Spark Thrift Server uses Spark dynamic executor allocation and hence hello `spark.executor.instances` is not used.</span></span> <span data-ttu-id="fc112-169">Em vez disso, utiliza servidor Thrift de Spark `spark.dynamicAllocation.minExecutors` e `spark.dynamicAllocation.maxExecutors` contagem de executor de Olá toospecify.</span><span class="sxs-lookup"><span data-stu-id="fc112-169">Instead, Spark Thrift Server uses `spark.dynamicAllocation.minExecutors` and `spark.dynamicAllocation.maxExecutors` toospecify hello executor count.</span></span> <span data-ttu-id="fc112-170">parâmetros de configuração de Olá `spark.executor.cores` e `spark.executor.memory` é utilizado o tamanho de executor de Olá toomodify.</span><span class="sxs-lookup"><span data-stu-id="fc112-170">hello configuration parameters `spark.executor.cores` and `spark.executor.memory` is used toomodify hello executor size.</span></span> <span data-ttu-id="fc112-171">Pode alterar estes parâmetros, como mostrado abaixo.</span><span class="sxs-lookup"><span data-stu-id="fc112-171">You can change these parameters as shown below.</span></span>

* <span data-ttu-id="fc112-172">Expanda Olá **avançadas sparkconf de thrift de spark** parâmetros de Olá categoria tooupdate `spark.dynamicAllocation.minExecutors`, `spark.dynamicAllocation.maxExecutors`, e `spark.executor.memory`.</span><span class="sxs-lookup"><span data-stu-id="fc112-172">Expand hello **Advanced spark-thrift-sparkconf** category tooupdate hello parameters `spark.dynamicAllocation.minExecutors`, `spark.dynamicAllocation.maxExecutors`, and `spark.executor.memory`.</span></span>

    ![Configurar o servidor thrift de Spark](./media/hdinsight-apache-spark-resource-manager/spark-thrift-server-1.png)    
* <span data-ttu-id="fc112-174">Expanda Olá **personalizada spark-thrift-sparkconf** parâmetro de Olá categoria tooupdate `spark.executor.cores`.</span><span class="sxs-lookup"><span data-stu-id="fc112-174">Expand hello **Custom spark-thrift-sparkconf** category tooupdate hello parameter `spark.executor.cores`.</span></span>

    ![Configurar o servidor thrift de Spark](./media/hdinsight-apache-spark-resource-manager/spark-thrift-server-2.png)

### <a name="how-do-i-change-hello-driver-memory-of-hello-spark-thrift-server"></a><span data-ttu-id="fc112-176">Como posso alterar Olá controladores de memória de Olá servidor Thrift de Spark?</span><span class="sxs-lookup"><span data-stu-id="fc112-176">How do I change hello driver memory of hello Spark Thrift Server?</span></span>
<span data-ttu-id="fc112-177">Memória do servidor Thrift de Spark controlador é configurado too25% do tamanho do nó principal RAM Olá, fornecida Olá tamanho de RAM total do nó principal Olá é superior a 14GB.</span><span class="sxs-lookup"><span data-stu-id="fc112-177">Spark Thrift Server driver memory is configured too25% of hello head node RAM size, provided hello total RAM size of hello head node is greater than 14GB.</span></span> <span data-ttu-id="fc112-178">Pode utilizar Olá configuração de memória do Ambari IU toochange Olá controladores, como mostrado abaixo.</span><span class="sxs-lookup"><span data-stu-id="fc112-178">You can use hello Ambari UI toochange hello driver memory configuration, as shown below.</span></span>

* <span data-ttu-id="fc112-179">No Olá Ambari IU clique **Spark**, clique em **folhas**, expanda **avançadas spark env**e, em seguida, forneça o valor de Olá para **spark_thrift_cmd_opts**.</span><span class="sxs-lookup"><span data-stu-id="fc112-179">From hello Ambari UI click **Spark**, click **Configs**, expand **Advanced spark-env**, and then provide hello value for **spark_thrift_cmd_opts**.</span></span>

    ![Configurar o servidor thrift de Spark RAM](./media/hdinsight-apache-spark-resource-manager/spark-thrift-server-ram.png)

## <a name="i-do-not-use-bi-with-spark-cluster-how-do-i-take-hello-resources-back"></a><span data-ttu-id="fc112-181">Não utilizo BI com um cluster do Spark.</span><span class="sxs-lookup"><span data-stu-id="fc112-181">I do not use BI with Spark cluster.</span></span> <span data-ttu-id="fc112-182">Como devo efetuar recursos Olá novamente?</span><span class="sxs-lookup"><span data-stu-id="fc112-182">How do I take hello resources back?</span></span>
<span data-ttu-id="fc112-183">Uma vez que utilizamos alocação dinâmica Spark, hello apenas os recursos que são consumidos pelo servidor thrift são recursos Olá para Olá duas aplicações modelos de estrutura mestres.</span><span class="sxs-lookup"><span data-stu-id="fc112-183">Since we use Spark dynamic allocation, hello only resources that are consumed by thrift server are hello resources for hello two application masters.</span></span> <span data-ttu-id="fc112-184">tooreclaim Olá, estes recursos que tem de parar serviços do servidor Thrift em execução no cluster de Olá.</span><span class="sxs-lookup"><span data-stu-id="fc112-184">tooreclaim these resources you must stop hello Thrift Server services running on hello cluster.</span></span>

1. <span data-ttu-id="fc112-185">Olá IU do Ambari, no painel esquerdo do Olá, clique em **Spark**.</span><span class="sxs-lookup"><span data-stu-id="fc112-185">From hello Ambari UI, from hello left pane, click **Spark**.</span></span>
2. <span data-ttu-id="fc112-186">Na página seguinte Olá, clique em **servidores de Thrift de Spark**.</span><span class="sxs-lookup"><span data-stu-id="fc112-186">In hello next page, click **Spark Thrift Servers**.</span></span>

    ![Reinicie o servidor thrift](./media/hdinsight-apache-spark-resource-manager/restart-thrift-server-1.png)
3. <span data-ttu-id="fc112-188">Deverá ver dois headnodes Olá no qual Olá servidor Thrift de Spark está em execução.</span><span class="sxs-lookup"><span data-stu-id="fc112-188">You should see hello two headnodes on which hello Spark Thrift Server is running.</span></span> <span data-ttu-id="fc112-189">Clique das Olá headnodes.</span><span class="sxs-lookup"><span data-stu-id="fc112-189">Click one of hello headnodes.</span></span>

    ![Reinicie o servidor thrift](./media/hdinsight-apache-spark-resource-manager/restart-thrift-server-2.png)
4. <span data-ttu-id="fc112-191">página seguinte Olá apresenta uma lista de todos os serviços de Olá em execução nesse headnode.</span><span class="sxs-lookup"><span data-stu-id="fc112-191">hello next page lists all hello services running on that headnode.</span></span> <span data-ttu-id="fc112-192">Na lista de Olá clique Olá pendente botão seguinte tooSpark servidor Thrift e, em seguida, clique em **parar**.</span><span class="sxs-lookup"><span data-stu-id="fc112-192">From hello list click hello drop-down button next tooSpark Thrift Server, and then click **Stop**.</span></span>

    ![Reinicie o servidor thrift](./media/hdinsight-apache-spark-resource-manager/restart-thrift-server-3.png)
5. <span data-ttu-id="fc112-194">Repita estes passos em Olá, bem como outra headnode.</span><span class="sxs-lookup"><span data-stu-id="fc112-194">Repeat these steps on hello other headnode as well.</span></span>

## <a name="my-jupyter-notebooks-are-not-running-as-expected-how-can-i-restart-hello-service"></a><span data-ttu-id="fc112-195">A minha blocos de notas do Jupyter não estão em execução conforme esperado.</span><span class="sxs-lookup"><span data-stu-id="fc112-195">My Jupyter notebooks are not running as expected.</span></span> <span data-ttu-id="fc112-196">Como reiniciar o serviço de Olá?</span><span class="sxs-lookup"><span data-stu-id="fc112-196">How can I restart hello service?</span></span>
<span data-ttu-id="fc112-197">Inicie Olá IU da Web do Ambari, conforme mostrado acima.</span><span class="sxs-lookup"><span data-stu-id="fc112-197">Launch hello Ambari Web UI as shown above.</span></span> <span data-ttu-id="fc112-198">No painel de navegação esquerdo Olá, clique em **Jupyter**, clique em **serviço ações**e, em seguida, clique em **todas reinicie**.</span><span class="sxs-lookup"><span data-stu-id="fc112-198">From hello left navigation pane, click **Jupyter**, click **Service Actions**, and then click **Restart All**.</span></span> <span data-ttu-id="fc112-199">Isto irá iniciar o serviço do Jupyter de Olá em todos os Olá headnodes.</span><span class="sxs-lookup"><span data-stu-id="fc112-199">This will start hello Jupyter service on all hello headnodes.</span></span>

    ![Restart Jupyter](./media/hdinsight-apache-spark-resource-manager/restart-jupyter.png "Restart Jupyter")

## <a name="how-do-i-know-if-i-am-running-out-of-resources"></a><span data-ttu-id="fc112-200">Como saber se estiver a ficar sem recursos?</span><span class="sxs-lookup"><span data-stu-id="fc112-200">How do I know if I am running out of resources?</span></span>
<span data-ttu-id="fc112-201">Inicie Olá IU do Yarn, conforme mostrado acima.</span><span class="sxs-lookup"><span data-stu-id="fc112-201">Launch hello Yarn UI as shown above.</span></span> <span data-ttu-id="fc112-202">Na tabela de métricas de Cluster por cima do ecrã de Olá, verifique os valores de **memória utilizada** e **memória Total** colunas.</span><span class="sxs-lookup"><span data-stu-id="fc112-202">In Cluster Metrics table on top of hello screen, check values of **Memory Used** and **Memory Total** columns.</span></span> <span data-ttu-id="fc112-203">Se os valores de Olá 2 forem muito fechar, pode não existir suficiente aplicação seguinte do toostart Olá de recursos.</span><span class="sxs-lookup"><span data-stu-id="fc112-203">If hello 2 values are very close, there might not be enough resources toostart hello next application.</span></span> <span data-ttu-id="fc112-204">Olá mesmo se aplica toohello **VCores utilizado** e **VCores Total** colunas.</span><span class="sxs-lookup"><span data-stu-id="fc112-204">hello same applies toohello **VCores Used** and **VCores Total** columns.</span></span> <span data-ttu-id="fc112-205">Além disso, na vista de principais de Olá, se existir uma aplicação stayed no **ACEITES** estado e não vão transitar para **executar** nem **falha** Estado, isto também pode ser uma indicação que não está a obter suficiente toostart de recursos.</span><span class="sxs-lookup"><span data-stu-id="fc112-205">Also, in hello main view, if there is an application stayed in **ACCEPTED** state and not transitioning into **RUNNING** nor **FAILED** state, this could also be an indication that it is not getting enough resources toostart.</span></span>

    ![Resource Limit](./media/hdinsight-apache-spark-resource-manager/resource-limit.png "Resource Limit")

## <a name="how-do-i-kill-a-running-application-toofree-up-resource"></a><span data-ttu-id="fc112-206">Como eliminar uma execução toofree de aplicação dos recursos?</span><span class="sxs-lookup"><span data-stu-id="fc112-206">How do I kill a running application toofree up resource?</span></span>
1. <span data-ttu-id="fc112-207">No Olá IU do Yarn, a partir do painel esquerdo do Olá, clique em **executar**.</span><span class="sxs-lookup"><span data-stu-id="fc112-207">In hello Yarn UI, from hello left panel, click **Running**.</span></span> <span data-ttu-id="fc112-208">Na lista de Olá das aplicações em execução, determinar Olá aplicação toobe desativados e clique em Olá **ID**.</span><span class="sxs-lookup"><span data-stu-id="fc112-208">From hello list of running applications, determine hello application toobe killed and click on hello **ID**.</span></span>

    <span data-ttu-id="fc112-209">![Kill App1](./media/hdinsight-apache-spark-resource-manager/kill-app1.png "Kill App1")</span><span class="sxs-lookup"><span data-stu-id="fc112-209">![Kill App1](./media/hdinsight-apache-spark-resource-manager/kill-app1.png "Kill App1")</span></span>

2. <span data-ttu-id="fc112-210">Clique em **Kill aplicação** Olá canto superior direito, em seguida, clique em **OK**.</span><span class="sxs-lookup"><span data-stu-id="fc112-210">Click **Kill Application** on hello top right corner, then click **OK**.</span></span>

    <span data-ttu-id="fc112-211">![Kill App2](./media/hdinsight-apache-spark-resource-manager/kill-app2.png "Kill App2")</span><span class="sxs-lookup"><span data-stu-id="fc112-211">![Kill App2](./media/hdinsight-apache-spark-resource-manager/kill-app2.png "Kill App2")</span></span>

## <a name="see-also"></a><span data-ttu-id="fc112-212">Consultar também</span><span class="sxs-lookup"><span data-stu-id="fc112-212">See also</span></span>
* [<span data-ttu-id="fc112-213">Controlar e depurar tarefas em execução num cluster do Apache Spark do HDInsight</span><span class="sxs-lookup"><span data-stu-id="fc112-213">Track and debug jobs running on an Apache Spark cluster in HDInsight</span></span>](hdinsight-apache-spark-job-debugging.md)

### <a name="for-data-analysts"></a><span data-ttu-id="fc112-214">Para os analistas de dados</span><span class="sxs-lookup"><span data-stu-id="fc112-214">For data analysts</span></span>

* [<span data-ttu-id="fc112-215">Spark com Machine Learning: Utilizar o Spark no HDInsight para analisar a temperatura do edifício com dados de AVAC</span><span class="sxs-lookup"><span data-stu-id="fc112-215">Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)
* [<span data-ttu-id="fc112-216">Spark com Machine Learning: utilizar o Spark no HDInsight toopredict inspeções alimentares</span><span class="sxs-lookup"><span data-stu-id="fc112-216">Spark with Machine Learning: Use Spark in HDInsight toopredict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)
* [<span data-ttu-id="fc112-217">Análise de registos de sites com o Spark no HDInsight</span><span class="sxs-lookup"><span data-stu-id="fc112-217">Website log analysis using Spark in HDInsight</span></span>](hdinsight-apache-spark-custom-library-website-log-analysis.md)
* [<span data-ttu-id="fc112-218">Análise de dados telemétricos do Application Insight com o Spark no HDInsight</span><span class="sxs-lookup"><span data-stu-id="fc112-218">Application Insight telemetry data analysis using Spark in HDInsight</span></span>](hdinsight-spark-analyze-application-insight-logs.md)
* [<span data-ttu-id="fc112-219">Utilizar Caffe no Azure HDInsight Spark para aprender profunda distribuída</span><span class="sxs-lookup"><span data-stu-id="fc112-219">Use Caffe on Azure HDInsight Spark for distributed deep learning</span></span>](hdinsight-deep-learning-caffe-spark.md)

### <a name="for-spark-developers"></a><span data-ttu-id="fc112-220">Para programadores do Spark</span><span class="sxs-lookup"><span data-stu-id="fc112-220">For Spark developers</span></span>

* [<span data-ttu-id="fc112-221">Criar uma aplicação autónoma com o Scala</span><span class="sxs-lookup"><span data-stu-id="fc112-221">Create a standalone application using Scala</span></span>](hdinsight-apache-spark-create-standalone-application.md)
* [<span data-ttu-id="fc112-222">Executar tarefas remotamente num cluster do Spark com o Livy</span><span class="sxs-lookup"><span data-stu-id="fc112-222">Run jobs remotely on a Spark cluster using Livy</span></span>](hdinsight-apache-spark-livy-rest-interface.md)
* [<span data-ttu-id="fc112-223">Utilizar o plug-in ferramentas do HDInsight para o IntelliJ IDEA toocreate e submeter aplicações do Spark Scala</span><span class="sxs-lookup"><span data-stu-id="fc112-223">Use HDInsight Tools Plugin for IntelliJ IDEA toocreate and submit Spark Scala applications</span></span>](hdinsight-apache-spark-intellij-tool-plugin.md)
* [<span data-ttu-id="fc112-224">Transmissão em Fluxo do Spark: Utilizar o Spark no HDInsight para criar aplicações de transmissão em fluxo em tempo real</span><span class="sxs-lookup"><span data-stu-id="fc112-224">Spark Streaming: Use Spark in HDInsight for building real-time streaming applications</span></span>](hdinsight-apache-spark-eventhub-streaming.md)
* [<span data-ttu-id="fc112-225">Utilizar o plug-in ferramentas do HDInsight para aplicações do Spark IntelliJ IDEA toodebug remotamente</span><span class="sxs-lookup"><span data-stu-id="fc112-225">Use HDInsight Tools Plugin for IntelliJ IDEA toodebug Spark applications remotely</span></span>](hdinsight-apache-spark-intellij-tool-plugin-debug-jobs-remotely.md)
* [<span data-ttu-id="fc112-226">Utilizar blocos de notas do Zeppelin com um cluster do Spark no HDInsight</span><span class="sxs-lookup"><span data-stu-id="fc112-226">Use Zeppelin notebooks with a Spark cluster on HDInsight</span></span>](hdinsight-apache-spark-zeppelin-notebook.md)
* [<span data-ttu-id="fc112-227">Kernels disponíveis para o bloco de notas do Jupyter no cluster do Spark para o HDInsight</span><span class="sxs-lookup"><span data-stu-id="fc112-227">Kernels available for Jupyter notebook in Spark cluster for HDInsight</span></span>](hdinsight-apache-spark-jupyter-notebook-kernels.md)
* [<span data-ttu-id="fc112-228">Utilizar pacotes externos com blocos de notas do Jupyter</span><span class="sxs-lookup"><span data-stu-id="fc112-228">Use external packages with Jupyter notebooks</span></span>](hdinsight-apache-spark-jupyter-notebook-use-external-packages.md)
* [<span data-ttu-id="fc112-229">Instalar o Jupyter no seu computador e ligue tooan cluster do HDInsight Spark</span><span class="sxs-lookup"><span data-stu-id="fc112-229">Install Jupyter on your computer and connect tooan HDInsight Spark cluster</span></span>](hdinsight-apache-spark-jupyter-notebook-install-locally.md)
